{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Build Baseline Location Classifier\\nApproaches:\\n- instance representation in form of 'bag' of words \\n    - features: word frequencies, metadata \\n    - exclude rare words in data set (used by less than 3 users )\\n- gramatical structure with NLP\\n- model instances in terms of authors instead of documents \\n\\n\\n- Baseline Classifier: Naive Bayes Model ()\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Build Baseline Location Classifier\n",
    "Approaches:\n",
    "- instance representation in form of 'bag' of words \n",
    "    - features: word frequencies, metadata \n",
    "    - exclude rare words in data set (used by less than 3 users )\n",
    "- gramatical structure with NLP\n",
    "- model instances in terms of authors instead of documents \n",
    "\n",
    "\n",
    "- Baseline Classifier: Naive Bayes Model ()\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from os import path, getcwd\n",
    "from collections import defaultdict\n",
    "import preprocessor as p\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "import re, string\n",
    "from validators import url\n",
    "from info_gain.info_gain import info_gain_ratio\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from nltk.stem import SnowballStemmer\n",
    "# nltk.download('english')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Instance_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>\\ud83c\\udf17 @ Melbourne, Victoria, Australia ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>@theage Of course it costs more, minimum stand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Hope people make just as much noise as they di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perth</td>\n",
       "      <td>Pouring the perfect Prosecco \\ud83e\\udd42\\ud83...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Perth</td>\n",
       "      <td>$LNY losing traction at 0.014, see this retrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>\\u0e44\\u0e21\\u0e48\\u0e44\\u0e2b\\u0e27\\u0e41\\u0e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>@ashleighjayy_ Me @ this bitch https://t.co/8J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>@AnaOLFan I \\u2764\\ufe0f you - I could never b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sydney</td>\n",
       "      <td>@ihatejoelkim Welcome to Australia! Hoping you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Mea evolve conference @markbouris session. I L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>First taste of Winter in Autumn https://t.co/0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>\\u0643\\u064a\\u0641 \\u064a\\u0634\\u0648\\u0641 \\u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sydney</td>\n",
       "      <td>#SelfieSunday #Lost #Tabby &amp;amp; White/Caramel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>@artsdesire Give her credit, she looks incredi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sydney</td>\n",
       "      <td>@Pringster78 @Chadderbox2018 I kind of do the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Perth</td>\n",
       "      <td>@gramercypark It\\u2019s great isn\\u2019t it?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sydney</td>\n",
       "      <td>https://t.co/RT37Cj5KRF  I date her, not MJ xo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Perth</td>\n",
       "      <td>@AussieAndyCx @ImScaredq Deadest Kane would de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sydney</td>\n",
       "      <td>if i see got spoilers (and esp not tagged or a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>\\u0639\\u064e\\u0644\\u064a\\u0643 \\u0639\\u0648\\u0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Perth</td>\n",
       "      <td>@pleaseuseaussie @RodS108443078 Hope so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>x2 babe \\ud83d\\ude2b biggest scam I tell you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>@idgimaddy @EXOGlobal @B_hundred_Hyun @1992050...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Perth</td>\n",
       "      <td>sbren sbeve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Sydney</td>\n",
       "      <td>Grassy, bitter (Kiwi) hops, clean - Drinking a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>@FatherBob  Father Bob,  Thankyou I went to an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>30th Birthday Dinner \\ud83e\\udd42\\ud83c\\udf88\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Perth</td>\n",
       "      <td>@clementine_ford Us fellas were all drawn to i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Perth</td>\n",
       "      <td>https://t.co/nejALF6216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>KOKO BUNNY! The Easter Bunny arrived at my doo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103335</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Wow, I\\u2019m not very good at getting the pic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103336</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>I gather the Govt wants to further clog up Pun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103337</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Visualization is the key to success. Dream big...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103338</th>\n",
       "      <td>Sydney</td>\n",
       "      <td>Countries I\\u2019ve Been To:  Fiji \\ud83c\\udde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103339</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>@TaodeHaas @carolemorrissey Yes i agree....   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103340</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>@Wiley_Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103341</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Unbelievable @RiflePete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103342</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Thanks @TheJosephNaim for coming to see @Jerse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103343</th>\n",
       "      <td>Sydney</td>\n",
       "      <td>@HarryTrevor8888 @blondebonnie94 It is incompa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103344</th>\n",
       "      <td>Perth</td>\n",
       "      <td>The day before the budget, Sportsbet had odds ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103345</th>\n",
       "      <td>Perth</td>\n",
       "      <td>@sophie_walsh9 Where was this Sophie ? He was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103346</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>People who are not scientists but who question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103347</th>\n",
       "      <td>Sydney</td>\n",
       "      <td>My mom came up to visit this morning and to ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103348</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>TS7 \\u2764\\ufe0f https://t.co/OQOaAft5Fg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103349</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>@iamtheoracle I know, I know. Those people are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103350</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>@StephanieLoveUK Already seen enough there\\u20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103351</th>\n",
       "      <td>Perth</td>\n",
       "      <td>@colinhussey22 gorillaz\\ud83d\\udc4c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103352</th>\n",
       "      <td>Sydney</td>\n",
       "      <td>@insufferablscot @tinyelbows_ Part of me think...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103353</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>@CDeLaFuentez Lol exactly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103354</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>@rmharmon2004 outside of the context ofwrestli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103355</th>\n",
       "      <td>Sydney</td>\n",
       "      <td>@KirstyWebeck So SMASH it Kirsty!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103356</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>\\u0e04\\u0e34\\u0e14\\u0e16\\u0e36\\u0e07\\u0e2b\\u0e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103357</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>@tbdalton5 That they are! I have had 2 in my l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103358</th>\n",
       "      <td>Perth</td>\n",
       "      <td>@GrayConnolly @GemmaTognini @ElizaJBarr You\\u2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103359</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>@australian @IzzyFolau very interesting that y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103360</th>\n",
       "      <td>Sydney</td>\n",
       "      <td>Solzinho bom pra ir na praia hoje</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103361</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>@suzdavies13 Of me??? Thank you, surely you do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103362</th>\n",
       "      <td>Perth</td>\n",
       "      <td>@GraceSpelman have you heard of Dune? seen som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103363</th>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Id bang you harder than an old Chevrolet door</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103364</th>\n",
       "      <td>Sydney</td>\n",
       "      <td>@Mezmfield @chief_comanche @Utopiana @fraser_a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103360 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Location                                               Text\n",
       "Instance_ID                                                              \n",
       "1            Melbourne  \\ud83c\\udf17 @ Melbourne, Victoria, Australia ...\n",
       "2            Melbourne  @theage Of course it costs more, minimum stand...\n",
       "3             Brisbane  Hope people make just as much noise as they di...\n",
       "4                Perth  Pouring the perfect Prosecco \\ud83e\\udd42\\ud83...\n",
       "5                Perth  $LNY losing traction at 0.014, see this retrac...\n",
       "6            Melbourne  \\u0e44\\u0e21\\u0e48\\u0e44\\u0e2b\\u0e27\\u0e41\\u0e...\n",
       "7            Melbourne  @ashleighjayy_ Me @ this bitch https://t.co/8J...\n",
       "8            Melbourne  @AnaOLFan I \\u2764\\ufe0f you - I could never b...\n",
       "9               Sydney  @ihatejoelkim Welcome to Australia! Hoping you...\n",
       "10            Brisbane  Mea evolve conference @markbouris session. I L...\n",
       "11           Melbourne  First taste of Winter in Autumn https://t.co/0...\n",
       "12            Brisbane  \\u0643\\u064a\\u0641 \\u064a\\u0634\\u0648\\u0641 \\u...\n",
       "13              Sydney  #SelfieSunday #Lost #Tabby &amp; White/Caramel...\n",
       "14            Brisbane  @artsdesire Give her credit, she looks incredi...\n",
       "15              Sydney  @Pringster78 @Chadderbox2018 I kind of do the ...\n",
       "16               Perth       @gramercypark It\\u2019s great isn\\u2019t it?\n",
       "17              Sydney  https://t.co/RT37Cj5KRF  I date her, not MJ xo...\n",
       "18               Perth  @AussieAndyCx @ImScaredq Deadest Kane would de...\n",
       "19              Sydney  if i see got spoilers (and esp not tagged or a...\n",
       "20           Melbourne  \\u0639\\u064e\\u0644\\u064a\\u0643 \\u0639\\u0648\\u0...\n",
       "21               Perth           @pleaseuseaussie @RodS108443078 Hope so.\n",
       "22            Brisbane      x2 babe \\ud83d\\ude2b biggest scam I tell you.\n",
       "23           Melbourne  @idgimaddy @EXOGlobal @B_hundred_Hyun @1992050...\n",
       "24               Perth                                        sbren sbeve\n",
       "25              Sydney  Grassy, bitter (Kiwi) hops, clean - Drinking a...\n",
       "26           Melbourne  @FatherBob  Father Bob,  Thankyou I went to an...\n",
       "27            Brisbane  30th Birthday Dinner \\ud83e\\udd42\\ud83c\\udf88\\...\n",
       "28               Perth  @clementine_ford Us fellas were all drawn to i...\n",
       "29               Perth                            https://t.co/nejALF6216\n",
       "30           Melbourne  KOKO BUNNY! The Easter Bunny arrived at my doo...\n",
       "...                ...                                                ...\n",
       "103335       Melbourne  Wow, I\\u2019m not very good at getting the pic...\n",
       "103336       Melbourne  I gather the Govt wants to further clog up Pun...\n",
       "103337        Brisbane  Visualization is the key to success. Dream big...\n",
       "103338          Sydney  Countries I\\u2019ve Been To:  Fiji \\ud83c\\udde...\n",
       "103339        Brisbane  @TaodeHaas @carolemorrissey Yes i agree....   ...\n",
       "103340        Brisbane                                      @Wiley_Health\n",
       "103341        Brisbane                            Unbelievable @RiflePete\n",
       "103342       Melbourne  Thanks @TheJosephNaim for coming to see @Jerse...\n",
       "103343          Sydney  @HarryTrevor8888 @blondebonnie94 It is incompa...\n",
       "103344           Perth  The day before the budget, Sportsbet had odds ...\n",
       "103345           Perth  @sophie_walsh9 Where was this Sophie ? He was ...\n",
       "103346       Melbourne  People who are not scientists but who question...\n",
       "103347          Sydney  My mom came up to visit this morning and to ru...\n",
       "103348       Melbourne           TS7 \\u2764\\ufe0f https://t.co/OQOaAft5Fg\n",
       "103349       Melbourne  @iamtheoracle I know, I know. Those people are...\n",
       "103350       Melbourne  @StephanieLoveUK Already seen enough there\\u20...\n",
       "103351           Perth                @colinhussey22 gorillaz\\ud83d\\udc4c\n",
       "103352          Sydney  @insufferablscot @tinyelbows_ Part of me think...\n",
       "103353       Melbourne                          @CDeLaFuentez Lol exactly\n",
       "103354        Brisbane  @rmharmon2004 outside of the context ofwrestli...\n",
       "103355          Sydney                  @KirstyWebeck So SMASH it Kirsty!\n",
       "103356       Melbourne  \\u0e04\\u0e34\\u0e14\\u0e16\\u0e36\\u0e07\\u0e2b\\u0e...\n",
       "103357       Melbourne  @tbdalton5 That they are! I have had 2 in my l...\n",
       "103358           Perth  @GrayConnolly @GemmaTognini @ElizaJBarr You\\u2...\n",
       "103359       Melbourne  @australian @IzzyFolau very interesting that y...\n",
       "103360          Sydney                  Solzinho bom pra ir na praia hoje\n",
       "103361       Melbourne  @suzdavies13 Of me??? Thank you, surely you do...\n",
       "103362           Perth  @GraceSpelman have you heard of Dune? seen som...\n",
       "103363       Melbourne      Id bang you harder than an old Chevrolet door\n",
       "103364          Sydney  @Mezmfield @chief_comanche @Utopiana @fraser_a...\n",
       "\n",
       "[103360 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdir = path.join(getcwd(), \"2019S1-proj2-datah\")\n",
    "\n",
    "train_data = \"train-raw.tsv\"\n",
    "test_data = \"test-raw.tsv\"\n",
    "dev_data = \"dev-raw.tsv\"\n",
    "\n",
    "train_fpath = path.join(fdir, train_data)\n",
    "\n",
    "train = pd.read_csv(train_fpath, sep=\"\\t\", index_col=\"Instance_ID\", encoding=\"utf_8\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = ['Text']\n",
    "output = 'Location'\n",
    "x = train[inputs]\n",
    "y = train[output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoTagger:\n",
    "    _FEATURE_SELECTION = [\"info_gain_ratio\", \"word_locality_heuristic\", 'chi_squared', 'mutial_info']\n",
    "    _VOTING_STRATEGY = [\"simple_voting\", \"bagging\", \"stacking\", \"random_forest\", \"boosting\"]\n",
    "    _CLASSIFIERS = [\"MultinomialNB\", \"SVM\", \"SemiSupervised\", \"KNN\"]\n",
    "                          \n",
    "    def __init__(self, classifier_set=[\"MultinomialNB\"], voting_strategy=\"simple_voting\", feature_selection=\"IGR\", seed=\"12345\"):\n",
    "        self.exclude = set()\n",
    "        self.classifier_set = classifier_set # MultinomialNB, SVM\n",
    "        self.stopwords = set(stopwords.words('english'))\n",
    "        self.stemmer = SnowballStemmer('english')\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    def train(self, x, y):\n",
    "        self.classes = y.unique()\n",
    "        x = self.preprocess(x, train=True)\n",
    "        return x\n",
    "    \n",
    "    def test(self, x, y):\n",
    "#         self.preprocess(x, y)\n",
    "        pass\n",
    "    \n",
    "    def predict(self, x):\n",
    "#         self.preprocess(x, y)\n",
    "        pass\n",
    "    \n",
    "    def evaluate(self, x, y):\n",
    "#         y_pred = self.predict(y)\n",
    "#         cross validation\n",
    "        pass\n",
    "    \n",
    "    def preprocess(self, x, train=False):\n",
    "        \"\"\"\n",
    "         - Filter rare words (urls, typos rare names, punctuation symbols)\n",
    "         - calculate word frequencies \n",
    "         - metadata\n",
    "        \"\"\"\n",
    "#         if train:\n",
    "#             feature_weight(x)\n",
    "#             feature_selection(x)\n",
    "#       self.class_feature_sets = {label: defaultdict() for label in self.classes}\n",
    "        x = self.filter(x)\n",
    "        return x\n",
    "    \n",
    "    def filter(self, x):\n",
    "        \"\"\"\n",
    "        https://towardsdatascience.com/extracting-twitter-data-pre-processing-and-sentiment-analysis-using-python-3-0-7192bd8b47cf\n",
    "        \"\"\"\n",
    "        x.loc[x.index.values, 'Text'] = x['Text'].apply(self.filter_tweet)\n",
    "        return x        \n",
    "        \n",
    "    def feature_selection(self, x):\n",
    "        \"\"\"\n",
    "        (1) Information Gain Ratio (IGR) - across all states S, is \n",
    "            defined as the ratio between its information gain value IG, \n",
    "            which measures the decrease in class entropy H that w brings,\n",
    "            and its intrinsic entropy IV, which measures the entropy of \n",
    "            the presence versus the absence of that word\n",
    "            \n",
    "        (2) Word Locality Heuristic (WLH) - promotes words primarily \n",
    "            associated with one location. measure the probability of \n",
    "            a word occurring in a state, divided by its probability to \n",
    "            appear in any state. Then, for a given word w, we define the \n",
    "            WLH as the maximum such probability across all the states S\n",
    "        \"\"\"\n",
    "        if self.feature_selection == \"IGR\":\n",
    "#             return information_gain_ratio(x)\n",
    "             return\n",
    "        elif self.feature_selection == \"WLH\":\n",
    "            return word_locality_weight(x)\n",
    "#         elif seld\n",
    "        else:\n",
    "            print(\"Invalid Feature Selection method: {}. Choose one of \\\n",
    "            ({})\".format(self.feature_selection, \", \".join(GeoTagger._FEATURE_SELECTION)))\n",
    "        \n",
    "    def word_locality_weight(self, x):\n",
    "        \"\"\"\n",
    "        calculate frequencies of data \n",
    "        Measure frequency and divide by sum of freqencies of all words\n",
    "        \"\"\"\n",
    "    \n",
    "    def information_gain_ratio(self, x):\n",
    "#         return info_gain_ratio\n",
    "        pass\n",
    "        \n",
    "    def filter_tweet(self, tweet):\n",
    "        filtered = [self.filter_word(w) for w in tweet.split() if w not in self.stopwords]\n",
    "        return ' '.join(filtered)\n",
    "        \n",
    "    def filter_word(self, word):\n",
    "        word = word.lower()\n",
    "        # extract keywords from hashtag \n",
    "        if self._is_hyperlink(word):\n",
    "            print(word)\n",
    "            return ''\n",
    "        elif self._is_hashtag(word):\n",
    "            word = self._process_hashtag(word)\n",
    "        # potentially cross-reference individuals mentioned? or discard\n",
    "        elif self._is_mention(word):\n",
    "            word = self._process_mention(word)\n",
    "        # remove ascii characters \n",
    "        else:\n",
    "            word = self._ascii_to_unicode(word)\n",
    "            word = self._word_stem(word)\n",
    "            # .decode(\"unicode_escape\").encode('utf-8')\n",
    "            word = re.sub(r'[^\\w\\s]','', word)\n",
    "#         print(word)\n",
    "        return word\n",
    "                \n",
    "    def _is_hashtag(self, word):\n",
    "        if len(word) == 0:\n",
    "            return False\n",
    "        return word[0] == \"#\"\n",
    "    \n",
    "    def _is_mention(self, word):\n",
    "        if len(word) == 0:\n",
    "            return False\n",
    "        return word[0] == \"@\"\n",
    "    \n",
    "    def _is_hyperlink(self, word):\n",
    "        return url(word)\n",
    "    \n",
    "    def _process_hashtag(self, word):\n",
    "        return word[1:]\n",
    "    \n",
    "    def _process_mention(self, word):\n",
    "        return word[1:]\n",
    "    \n",
    "    def _ascii_to_unicode(self, word):\n",
    "        for uescape in re.findall(r'(\\\\u[0-9a-z]{4})', word):\n",
    "            try:\n",
    "#                 print(uescape.encode('utf-8').decode('unicode-escape'), type(uescape.encode('utf-8').decode('unicode-escape')))\n",
    "#                 word = re.sub(uescape, uescape.encode('utf-8'), word)\n",
    "#                 print(word)\n",
    "#                 print(uescape, type(uescape))\n",
    "                word = re.sub(uescape, ' ', word)  \n",
    "            except UnicodeDecodeError:\n",
    "                print(\"Failed to decode: {}\".format(uescape))\n",
    "        return word\n",
    "    \n",
    "    def _word_stem(self, word):\n",
    "        return self.stemmer.stem(word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance_ID\n",
      "1                    ud83cudf17 melbourn victoria australia\n",
      "2         theag cour cost minimum standard must anyth 50...\n",
      "3         hope peopl make much noi tpj shot definit dog ...\n",
      "4         pour perfect prosecco ud83eudd42ud83cudf7 ud83...\n",
      "5         lni lose traction 0014 see retrac back 0011 00...\n",
      "6         u0e44u0e21u0e48u0e44u0e2bu0e27u0e41u0e25u0e49u...\n",
      "7                                       ashleighjayy_ bitch\n",
      "8                 anaolfan u2764ufe0f could never offend xx\n",
      "9         ihatejoelkim welcom australia hope wonder time...\n",
      "10        mea evolv confer markbouri session learnt wiza...\n",
      "11                                 first tast winter autumn\n",
      "12        u0643u064au0641 u064au0634u0648u0641 u0627u063...\n",
      "13        selfiesunday lost tabbi amp whitecaramel cat m...\n",
      "14                          artsdesir give credit look incr\n",
      "15        pringster78 chadderbox2018 kind opposit love u...\n",
      "16                     gramercypark itu2019 great isnu2019t\n",
      "17                                           date mj xoxoxo\n",
      "18        aussieandycx imscaredq deadest kane would dead...\n",
      "19        see got spoiler esp tag anyth spoiler unfollow...\n",
      "20        u0639u064eu0644u064au0643 u0639u0648u0644u064f...\n",
      "21                        pleaseuseaussi rods108443078 hope\n",
      "22                     x2 babe ud83dude2b biggest scam tell\n",
      "23        idgimaddi exoglob b_hundred_hyun 19920506b4 we...\n",
      "24                                              sbren sbeve\n",
      "25        grassi bitter kiwi hop clean drink pale ale sh...\n",
      "26        fatherbob father bob thankyou went exclus priv...\n",
      "27        30th birthday dinner ud83eudd42ud83cudf88ud83d...\n",
      "28        clementine_ford us fella drawn thank sexi danc...\n",
      "29                                                         \n",
      "30        koko bunni easter bunni arriv door morn bear a...\n",
      "                                ...                        \n",
      "103335    wow iu2019m good get pic right size hope olgir...\n",
      "103336    gather govt want clog punt rd amp swan st inse...\n",
      "103337    visual key success dream big put action visual...\n",
      "103338    countri iu2019v fiji ud83cuddebud83cuddef aust...\n",
      "103339    taodehaa carolemorrissey yes agr peopl apathi ...\n",
      "103340                                         wiley_health\n",
      "103341                                    unbeliev riflepet\n",
      "103342    thank thejosephnaim come see jerseyboysoz yest...\n",
      "103343    harrytrevor8888 blondebonnie94 incompat wester...\n",
      "103344    day budget sportsbet odd labor win 118 lnp 450...\n",
      "103345         sophie_walsh9 sophi perth 18 month ago excel\n",
      "103346    peopl scientist question scienc scientist p15s...\n",
      "103347    mom came visit morn run around get thing eat food\n",
      "103348                                       ts7 u2764ufe0f\n",
      "103349         iamtheoracl know know peopl complet clueless\n",
      "103350    stephanieloveuk alreadi seen enough thereu2019...\n",
      "103351                     colinhussey22 gorillazud83dudc4c\n",
      "103352    insufferablscot tinyelbows_ part think youu201...\n",
      "103353                               cdelafuentez lol exact\n",
      "103354    rmharmon2004 outsid context ofwrestl twitteri ...\n",
      "103355                            kirstywebeck smash kirsti\n",
      "103356    u0e04u0e34u0e14u0e16u0e36u0e07u0e2bu0e25u0e34u...\n",
      "103357             tbdalton5 2 lifea femal child male adult\n",
      "103358    grayconnolli gemmatognini elizajbarr youu2019r...\n",
      "103359    australian izzyfolau interest get toilet boy w...\n",
      "103360                    solzinho bom pra ir na praia hoje\n",
      "103361    suzdavies13 thank sure donu2019t mean window c...\n",
      "103362    gracespelman heard dune seen peopl talk might ...\n",
      "103363                    id bang harder old chevrolet door\n",
      "103364    mezmfield chief_comanch utopiana fraser_an ud8...\n",
      "Name: Text, Length: 103360, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ninaaverill/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "gt = GeoTagger()\n",
    "x = gt.train(x, y)\n",
    "print(x['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
