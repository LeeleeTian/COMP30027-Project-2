{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Build Baseline Location Classifier\\nApproaches:\\n- instance representation in form of 'bag' of words \\n    - features: word frequencies, metadata \\n    - exclude rare words in data set (used by less than 3 users )\\n- gramatical structure with NLP\\n- model instances in terms of authors instead of documents \\n\\n\\n- Baseline Classifier: Naive Bayes Model ()\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Build Baseline Location Classifier\n",
    "Approaches:\n",
    "- instance representation in form of 'bag' of words \n",
    "    - features: word frequencies, metadata \n",
    "    - exclude rare words in data set (used by less than 3 users )\n",
    "- gramatical structure with NLP\n",
    "- model instances in terms of authors instead of documents \n",
    "\n",
    "\n",
    "- Baseline Classifier: Naive Bayes Model ()\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from os import path, getcwd\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import re, string\n",
    "from validators import url\n",
    "from info_gain.info_gain import info_gain_ratio\n",
    "\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# import preprocessor as p\n",
    "# nltk.download('english')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import data into pandas format from original csv/tsv file formats for \n",
    "the top 10/50/100 train/test/dev data \n",
    "\"\"\"\n",
    "\n",
    "fdir = path.join(getcwd(), \"2019S1-proj2-datah\")\n",
    "\n",
    "train_data = \"train-top10.csv\"\n",
    "test_data = \"test-top10.csv\"\n",
    "dev_data = \"dev-top10.csv\"\n",
    "\n",
    "train_fpath = path.join(fdir, train_data)\n",
    "test_fpath = path.join(fdir, test_data)\n",
    "dev_fpath = path.join(fdir, dev_data)\n",
    "\n",
    "train_top10 = pd.read_csv(train_fpath, encoding=\"utf_8\")\n",
    "test_top10 = pd.read_csv(test_fpath, encoding=\"utf_8\")\n",
    "dev_top10 = pd.read_csv(dev_fpath, encoding=\"utf_8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_top10.iloc[:, 1:35]\n",
    "test = train_top10.iloc[:, 1:35]\n",
    "dev = train_top10.iloc[:, 1:35]\n",
    "\n",
    "train_y = train.iloc[:, -1:]\n",
    "test_y = test.iloc[:, -1:]\n",
    "dev_y = dev.iloc[:, -1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoTagger:\n",
    "    _FEATURE_SELECTION = [\"info_gain_ratio\", \"word_locality_heuristic\", 'chi_squared', 'mutial_info']\n",
    "    _VOTING_STRATEGY = [\"simple_voting\", \"bagging\", \"stacking\", \"random_forest\", \"boosting\"]\n",
    "    _CLASSIFIERS = [\"Zero-R\", \"One-R\", \"Decision-Tree\", \"MultinomialNB\", \"SVM\", \"SemiSupervised\", \"KNN\"]\n",
    "    _EVALUATION_METRIC = [\"Accuracy\", \"Precision\", \"Recall\"]\n",
    "#     _EVALUATION METHOD = [\"Cross-Validation\"]\n",
    "                          \n",
    "    def __init__(self, classifier_set, voting_strategy, feature_selection, eval_metric, seed, train_x, train_y, dev_x, dev_y):\n",
    "        #self.stopwords = set(stopwords.words('english'))\n",
    "        #self.stemmer = WordNetLemmatizer('english')\n",
    "    \n",
    "        self.exclude = set()\n",
    "        self.classifier_set = classifier_set\n",
    "        self.voting_strategy = voting_strategy\n",
    "        self.feature_selection = feature_selection\n",
    "        self.eval_metric = eval_metric\n",
    "        np.random.seed(seed)\n",
    "        self.train_x = train_x\n",
    "        self.train_y= train_y\n",
    "        self.dev_x = dev_x\n",
    "        self.dev_y= dev_y\n",
    "            \n",
    "        #train classifier\n",
    "        print(len(self.classifier_set))\n",
    "        if len(self.classifier_set)>1: #classifier combination\n",
    "            clf = self.combine_classifiers(self.train_x, self.train_y, self.classifier_set)\n",
    "        else: #baseline classifier\n",
    "            clf = self.train_baseline(self.train_x, self.train_y, self.classifier_set[0])\n",
    "        \n",
    "        #predict the class labels of a set of test data\n",
    "        ybar = self.predict(clf, self.dev_x, self.classifier_set)\n",
    "        \n",
    "        #evaluate classifier performance\n",
    "        score = self.evaluate(ybar, self.dev_y, self.eval_metric)\n",
    "        \n",
    "        print(\"score\")\n",
    "    def train_baseline(self, X, y, classifier):\n",
    "        \"\"\"\n",
    "        trains a single classifier given the training data and their corresponding class labels\n",
    "        \"\"\"\n",
    "        print\n",
    "        print(GeoTagger._CLASSIFIERS.index(classifier))\n",
    "        \n",
    "        if GeoTagger._CLASSIFIERS.index(classifier)==0:\n",
    "            clf = DummyClassifier(strategy='most_frequent')\n",
    "            clf.fit(X, y)\n",
    "        elif GeoTagger._CLASSIFIERS.index(classifier)==1:\n",
    "            clf = DecisionTreeClassifier(max_depth=1, criterion=\"entropy\")\n",
    "            clf.fit(X,y)\n",
    "        elif GeoTagger._CLASSIFIERS.index(classifier)==2:\n",
    "            clf = DecisionTreeClassifier(max_depth=1, criterion=\"entropy\")\n",
    "            clf.fit(X,y)\n",
    "        elif GeoTagger._CLASSIFIERS.index(classifier)==3:\n",
    "            clf = MultinomialNB()\n",
    "            clf.fit(X,y)\n",
    "            print(clf)\n",
    "        return clf\n",
    "    \n",
    "    def combine_classifiers(self, X, y, classifiers):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, clf, X, classifier_type):\n",
    "        print(clf)\n",
    "#         print(X)\n",
    "#         print(classifier_type)\n",
    "        \n",
    "        if GeoTagger._CLASSIFIERS.index(classifier_type)==0:\n",
    "            predictions = clf.predict(X)\n",
    "        elif GeoTagger._CLASSIFIERS.index(classifier_type)==1:\n",
    "            predictions = clf.predict(X)\n",
    "        elif GeoTagger._CLASSIFIERS.index(classifier_type)==2:\n",
    "            predictions = clf.predict(X)\n",
    "        elif GeoTagger._CLASSIFIERS.index(classifier_type)==3:\n",
    "            print(\"kucing\")\n",
    "            predictions = clf.predict(X)\n",
    "            \n",
    "        return predictions\n",
    "    \n",
    "    def evaluate(self, ybar, y, metric):\n",
    "        #TODO: eval method\n",
    "        \n",
    "        if GeoTagger._EVALUATION_METRIC.index(metric) == 0:\n",
    "            score = accuracy_score(ybar, y)\n",
    "        if GeoTagger._EVALUATION_METRIC.index(metric) == 1:\n",
    "            score = accuracy_score(ybar, y)\n",
    "        if GeoTagger._EVALUATION_METRIC.index(metric) == 2:\n",
    "            score = accuracy_score(ybar, y)\n",
    "        if GeoTagger._EVALUATION_METRIC.index(metric) == 3:\n",
    "            score = accuracy_score(ybar, y)\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def preprocess(self, x, train=False):\n",
    "        \"\"\"\n",
    "         - Filter rare words (urls, typos rare names, punctuation symbols)\n",
    "         - calculate word frequencies \n",
    "         - metadata\n",
    "        \"\"\"\n",
    "#         if train:\n",
    "#             feature_weight(x)\n",
    "#             feature_selection(x)\n",
    "#       self.class_feature_sets = {label: defaultdict() for label in self.classes}\n",
    "        x = self.filter(x)\n",
    "        return x\n",
    "    \n",
    "    def filter(self, x):\n",
    "        \"\"\"\n",
    "        https://towardsdatascience.com/extracting-twitter-data-pre-processing-and-sentiment-analysis-using-python-3-0-7192bd8b47cf\n",
    "        \"\"\"\n",
    "        x.loc[x.index.values, 'Text'] = x['Text'].apply(self.filter_tweet)\n",
    "        return x        \n",
    "        \n",
    "    def feature_selection(self, x):\n",
    "        \"\"\"\n",
    "        (1) Information Gain Ratio (IGR) - across all states S, is \n",
    "            defined as the ratio between its information gain value IG, \n",
    "            which measures the decrease in class entropy H that w brings,\n",
    "            and its intrinsic entropy IV, which measures the entropy of \n",
    "            the presence versus the absence of that word\n",
    "            \n",
    "        (2) Word Locality Heuristic (WLH) - promotes words primarily \n",
    "            associated with one location. measure the probability of \n",
    "            a word occurring in a state, divided by its probability to \n",
    "            appear in any state. Then, for a given word w, we define the \n",
    "            WLH as the maximum such probability across all the states S\n",
    "        \"\"\"\n",
    "        if self.feature_selection == \"IGR\":\n",
    "#             return information_gain_ratio(x)\n",
    "             return\n",
    "        elif self.feature_selection == \"WLH\":\n",
    "            return word_locality_weight(x)\n",
    "#         elif seld\n",
    "        else:\n",
    "            print(\"Invalid Feature Selection method: {}. Choose one of \\\n",
    "            ({})\".format(self.feature_selection, \", \".join(GeoTagger._FEATURE_SELECTION)))\n",
    "        \n",
    "    def word_locality_weight(self, x):\n",
    "        \"\"\"\n",
    "        calculate frequencies of data \n",
    "        Measure frequency and divide by sum of freqencies of all words\n",
    "        \"\"\"\n",
    "    \n",
    "    def information_gain_ratio(self, x):\n",
    "#         return info_gain_ratio\n",
    "        pass\n",
    "        \n",
    "    def filter_tweet(self, tweet):\n",
    "        filtered = [self.filter_word(w) for w in tweet.split() if w not in self.stopwords]\n",
    "        return ' '.join(filtered)\n",
    "        \n",
    "    def filter_word(self, word):\n",
    "        word = word.lower()\n",
    "        # extract keywords from hashtag \n",
    "        if self._is_hyperlink(word):\n",
    "            print(word)\n",
    "            return ''\n",
    "        elif self._is_hashtag(word):\n",
    "            word = self._process_hashtag(word)\n",
    "        # potentially cross-reference individuals mentioned? or discard\n",
    "        elif self._is_mention(word):\n",
    "            word = self._process_mention(word)\n",
    "        # remove ascii characters \n",
    "        else:\n",
    "            word = self._ascii_to_unicode(word)\n",
    "            word = self._word_stem(word)\n",
    "            # .decode(\"unicode_escape\").encode('utf-8')\n",
    "            word = re.sub(r'[^\\w\\s]','', word)\n",
    "#         print(word)\n",
    "        return word\n",
    "                \n",
    "    def _is_hashtag(self, word):\n",
    "        if len(word) == 0:\n",
    "            return False\n",
    "        return word[0] == \"#\"\n",
    "    \n",
    "    def _is_mention(self, word):\n",
    "        if len(word) == 0:\n",
    "            return False\n",
    "        return word[0] == \"@\"\n",
    "    \n",
    "    def _is_hyperlink(self, word):\n",
    "        return url(word)\n",
    "    \n",
    "    def _process_hashtag(self, word):\n",
    "        return word[1:]\n",
    "    \n",
    "    def _process_mention(self, word):\n",
    "        return word[1:]\n",
    "    \n",
    "    def _ascii_to_unicode(self, word):\n",
    "        for uescape in re.findall(r'(\\\\u[0-9a-z]{4})', word):\n",
    "            try:\n",
    "#                 print(uescape.encode('utf-8').decode('unicode-escape'), type(uescape.encode('utf-8').decode('unicode-escape')))\n",
    "#                 word = re.sub(uescape, uescape.encode('utf-8'), word)\n",
    "#                 print(word)\n",
    "#                 print(uescape, type(uescape))\n",
    "                word = re.sub(uescape, ' ', word)  \n",
    "            except UnicodeDecodeError:\n",
    "                print(\"Failed to decode: {}\".format(uescape))\n",
    "        return word\n",
    "    \n",
    "    def _word_stem(self, word):\n",
    "        return self.stemmer.stem(word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "['MultinomialNB'] is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-210-0ba1d27115fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGeoTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"MultinomialNB\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"simple_voting\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mutual syntax\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Accuracy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdev_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-209-fd79efc19c97>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, classifier_set, voting_strategy, feature_selection, eval_metric, seed, train_x, train_y, dev_x, dev_y)\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombine_classifiers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#baseline classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_baseline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m#predict the class labels of a set of test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-209-fd79efc19c97>\u001b[0m in \u001b[0;36mtrain_baseline\u001b[1;34m(self, X, y, classifier)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \"\"\"\n\u001b[0;32m     41\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGeoTagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_CLASSIFIERS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mGeoTagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_CLASSIFIERS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: ['MultinomialNB'] is not in list"
     ]
    }
   ],
   "source": [
    "gt = GeoTagger([\"MultinomialNB\"], \"simple_voting\", \"mutual syntax\", \"Accuracy\", 500, train, train_y, dev, dev_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Resources\n",
    "- https://medium.com/@bedigunjit/simple-guide-to-text-classification-nlp-using-svm-and-naive-bayes-with-python-421db3a72d34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
