{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, string\n",
    "from os import path, getcwd\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier, GradientBoostingClassifier, BaggingClassifier, RandomForestClassifier\n",
    "\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import validators\n",
    "import nltk\n",
    "from info_gain.info_gain import info_gain_ratio\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdir = path.join(getcwd(), \"2019S1-proj2-datah\")\n",
    "\n",
    "train_data = \"train-raw.tsv\"\n",
    "test_data = \"test-raw.tsv\"\n",
    "dev_data = \"dev-raw.tsv\"\n",
    "\n",
    "train_fpath = path.join(fdir, train_data)\n",
    "test_fpath = path.join(fdir, test_data)\n",
    "dev_fpath = path.join(fdir, dev_data)\n",
    "\n",
    "train = pd.read_csv(train_fpath, encoding=\"utf_8\", delimiter=\"\\t\", index_col=\"Instance_ID\")\n",
    "test = pd.read_csv(test_fpath, encoding=\"utf_8\", delimiter=\"\\t\" , index_col=\"Instance_ID\")\n",
    "dev = pd.read_csv(dev_fpath, encoding=\"utf_8\", delimiter=\"\\t\" , index_col=\"Instance_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = 'Text'\n",
    "output = 'Location'\n",
    "x_train = train[inputs]\n",
    "y_train = train[output]\n",
    "x_test = test[inputs]\n",
    "y_test = test[output]\n",
    "x_dev = dev[inputs]\n",
    "y_dev = dev[output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoTagger:\n",
    "    _FEATURE_SELECTION = [\"baseline_10\", \"baseline_50\", \"baseline_100\", \"info_gain_ratio\", \"word_locality_heuristic\", \"tf_idf\"]\n",
    "    _ENSEMBLE_STRATEGY = [\"simple_voting\", \"meta_classification\", \"bagging\", \"random_forest\", \"boosting\"]\n",
    "    _CLASSIFIERS = [\"Zero-R\", \"One-R\", \"Decision-Tree\", \"MultinomialNB\", \"LinearSVM\", \"SemiSupervised\"]\n",
    "    _EVALUATION_METRIC = [\"accuracy\", \"precision_recall_f-score_with_macro\", \"precision_recall_f-score_with_micro\"]\n",
    "    \n",
    "    def __init__(self, inputs, target, classifier_set=[\"MultinomialNB\"], ensemble_strategy=\"simple_voting\", feature_selection_method=\"baseline_100\", seed=500, combine_classifiers=False, n_features=400):\n",
    "        self.n_features = n_features\n",
    "        self.inputs = inputs\n",
    "        self.target = target\n",
    "        self.classifier_set = classifier_set\n",
    "        self.ensemble_strategy = ensemble_strategy\n",
    "        self.feature_selection_method = feature_selection_method\n",
    "        self.seed = seed\n",
    "        np.random.seed(seed)\n",
    "        self.stemmer = SnowballStemmer('english')\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.combine_classifiers = combine_classifiers\n",
    "        self.classifier_set = self._generate_classifier_set(classifier_set)\n",
    "        self.combined_classifier = None if not self.combine_classifiers else self.generate_ensemble_classifier()\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        trains a classifier given the training data and their corresponding class labels\n",
    "        \"\"\"\n",
    "        self.classes = y.unique()\n",
    "        X = self.preprocess(X, y, train=True)\n",
    "        \n",
    "        if self.combine_classifiers:\n",
    "            self.combined_classifier.fit(X, y)\n",
    "        else:\n",
    "            for classifier in self.classifier_set.values():\n",
    "                classifier.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        predicts a set of classifiers given some development data\n",
    "        \"\"\"\n",
    "        X = self.preprocess(X)\n",
    "        print(X)\n",
    "        \n",
    "        if self.combine_classifiers:\n",
    "            return self.combined_classifier.predict(X)\n",
    "        else:\n",
    "            y_set = pd.DataFrame()\n",
    "\n",
    "            for name, classifier in self.classifier_set.items():\n",
    "                classifier_prediction = classifier.predict(X)\n",
    "                y_set[name] = classifier_prediction\n",
    "                \n",
    "        return y_set\n",
    "        \n",
    "    \n",
    "    def evaluate(self, ybar, y):\n",
    "        \"\"\"\n",
    "        evaluates a class' predictions given the correct class labels and an evaluation metric\n",
    "        \"\"\"\n",
    "#         if not metric in GeoTagger._EVALUATION_METRIC:\n",
    "#             print(\"Invalid Evaluation Metric: {}. Choose one of \\\n",
    "#             ({})\".format(metric, \", \".join(GeoTagger._EVALUATION_METRIC)))\n",
    "#             return\n",
    "            \n",
    "        score_set = defaultdict()\n",
    "        \n",
    "        if self.combine_classifiers:\n",
    "            classifiers = [self.ensemble_strategy, ]\n",
    "            ybar = pd.DataFrame(ybar, columns=classifiers, index = y.index)\n",
    "        else:\n",
    "            classifiers = self.classifier_set\n",
    "\n",
    "        for name, y_pred in ybar.items():\n",
    "            accuracy = accuracy_score(y, y_pred)\n",
    "            score_set[name] = accuracy \n",
    "#             report = classification_report(ybar, y, self.target)\n",
    "#             confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "        return score_set\n",
    "    \n",
    "    def cross_validation(self, X, y, metric):\n",
    "        score_set = defaultdict()\n",
    "        \n",
    "        X = self.preprocess(X)\n",
    "\n",
    "        if self.combine_classifiers:\n",
    "            classifiers = [self.ensemble_strategy, ]\n",
    "            ybar = pd.DataFrame(ybar, columns=classifiers, index = y.index)\n",
    "        else:\n",
    "            classifiers = self.classifier_set\n",
    "\n",
    "        for classifier in classifiers:\n",
    "            score_set[metric] = cross_validate(classifier, X, y, cv=10)\n",
    "        return score_set\n",
    "    \n",
    "    \n",
    "    def preprocess(self, X, y=None, train=False):\n",
    "        \"\"\"\n",
    "         - Filter rare words (urls, typos rare names, punctuation symbols)\n",
    "         - calculate word frequencies \n",
    "         - metadata\n",
    "        \"\"\"\n",
    "        X = self.filter(X)\n",
    "\n",
    "        if train:\n",
    "            self.feature_selection(X, y)\n",
    "        \n",
    "        X = self.bag_of_words(X)\n",
    "            \n",
    "        return X \n",
    "    \n",
    "    def bag_of_words(self, X):\n",
    "        _x = pd.DataFrame(\n",
    "            [[(word in text) for word in sorted(list(self.features))] for text in X.values],\n",
    "            index=X.index, \n",
    "            columns=self.features,\n",
    "            dtype=np.uint8\n",
    "        )        \n",
    "        return _x\n",
    "    \n",
    "    def generate_ensemble_classifier(self):\n",
    "        if not self.combine_classifiers:\n",
    "            return None\n",
    "        \n",
    "        if not self.ensemble_strategy in GeoTagger._ENSEMBLE_STRATEGY:\n",
    "            print(\"Invalid Ensemble Strategy Metric: {}. Choose one of \\\n",
    "            ({})\".format(metric, \", \".join(GeoTagger._ENSEMBLE_STRATEGY)))\n",
    "            return None\n",
    "        \n",
    "        if self.ensemble_strategy == \"simple_voting\":\n",
    "            combined_classifier = VotingClassifier(self.classifier_set.items(), 'hard')\n",
    "        elif self.ensemble_strategy == \"meta_classification\":\n",
    "            combined_classifier = MetaClassifier(self.classifier_set.items(), self.seed)\n",
    "        elif self.ensemble_strategy == \"bagging\":\n",
    "            base_classifier = DecisionTreeClassifier(max_features=None, max_leaf_nodes=999)\n",
    "            combined_classifier = BaggingClassifier(base_estimator=base_classifier, max_features=self.n_features, random_state=self.seed)\n",
    "        elif self.ensemble_strategy == \"random_forest\":\n",
    "            combined_classifier = RandomForestClassifier()\n",
    "        elif self.ensemble_strategy == \"boosting\":\n",
    "            combined_classifier = GradientBoostingClassifier()\n",
    "        \n",
    "        return combined_classifier\n",
    "        \n",
    "    \n",
    "    def _generate_classifier_set(self, classifiers):\n",
    "        classifier_set = defaultdict()\n",
    "        \n",
    "        for classifier in classifiers:\n",
    "            if not classifier in GeoTagger._CLASSIFIERS:\n",
    "                print(\"Invalid Classifier: {}. Choose one of \\\n",
    "                ({})\".format(classifier, \", \".join(GeoTagger._CLASSIFIERS)))\n",
    "                continue\n",
    "                \n",
    "            if classifier == \"Zero-R\":\n",
    "                classifier_set[classifier] = DummyClassifier(strategy='most_frequent', random_state=self.seed)\n",
    "            elif classifier == \"One-R\":\n",
    "                classifier_set[classifier] = DecisionTreeClassifier(max_depth=1, criterion=\"entropy\", random_state=self.seed)\n",
    "            elif classifier == \"Decision-Tree\":\n",
    "                classifier_set[classifier] = DecisionTreeClassifier(max_depth=None, criterion=\"entropy\", random_state=self.seed)\n",
    "            elif classifier == \"MultinomialNB\":\n",
    "                classifier_set[classifier] = MultinomialNB()\n",
    "            elif classifier == \"LinearSVM\":\n",
    "                classifier_set[classifier] = svm.LinearSVC(random_state=self.seed)\n",
    "            elif classifier == \"SemiSupervised\":\n",
    "                classifier_set[classifier] = LabelSpreading(kernel=\"knn\", n_neighbors=7, alpha=0.2)\n",
    "        return classifier_set\n",
    "                \n",
    "    def feature_selection(self, X, y):\n",
    "        \"\"\"\n",
    "        (1) Information Gain Ratio (IGR) - across all states S, is \n",
    "            defined as the ratio between its information gain value IG, \n",
    "            which measures the decrease in class entropy H that w brings,\n",
    "            and its intrinsic entropy IV, which measures the entropy of \n",
    "            the presence versus the absence of that word\n",
    "            \n",
    "        (2) Word Locality Heuristic (WLH) - promotes words primarily \n",
    "            associated with one location. measure the probability of \n",
    "            a word occurring in a state, divided by its probability to \n",
    "            appear in any state. Then, for a given word w, we define the \n",
    "            WLH as the maximum such probability across all the states S\n",
    "        \"\"\"\n",
    "        if self.feature_selection_method not in GeoTagger._FEATURE_SELECTION:\n",
    "            print(\"Invalid Feature Selection method: {}. Choose one of \\\n",
    "            ({})\".format(self.feature_selection_method, \", \".join(GeoTagger._FEATURE_SELECTION)))\n",
    "            return \n",
    "        \n",
    "        if self.feature_selection_method == \"baseline_10\":\n",
    "            self.baseline_heuristic(X, y, \"10\")\n",
    "        elif self.feature_selection_method == \"baseline_50\":\n",
    "            self.baseline_heuristic(X, y, \"50\")\n",
    "        elif self.feature_selection_method == \"baseline_100\":\n",
    "            self.baseline_heuristic(X, y, \"100\")\n",
    "        elif self.feature_selection_method == \"info_gain_ratio\":\n",
    "#             self.information_gain_ratio(x)\n",
    "            return\n",
    "        elif self.feature_selection_method == \"word_locality_heuristic\":\n",
    "            self.word_locality_weight(X, y)\n",
    "        elif self.feature_selection_method == \"tf_idf\":\n",
    "            self.term_frequency_inverse_city_frequency(X, y)\n",
    "\n",
    "    def baseline_heuristic(self, X, y, top_n):\n",
    "        feature_fpath = path.join(fdir, \"train-top\" + top_n + \".csv\")\n",
    "        \n",
    "        if not path.exists(feature_fpath):\n",
    "            print(\"Baseline Heuristic path {} does not exist\".format(feature_fpath))\n",
    "            return\n",
    "        \n",
    "        features = open(feature_fpath).readline()\n",
    "        features = features.split(\",\")\n",
    "        features.remove(\"Instance_ID\")\n",
    "        features.remove(\"Location\\n\")\n",
    "        self.features = set(features)\n",
    "\n",
    "    def word_locality_weight(self, X, y):\n",
    "        \"\"\"\n",
    "        calculate frequencies of data \n",
    "        Measure frequency and divide by sum of freqencies of all words\n",
    "        \"\"\"\n",
    "        locations = self.classes + ['Total',]\n",
    "        word_locality_features = {label: defaultdict() for label in locations}\n",
    "        word_locality_weight = {label: defaultdict() for label in self.classes}\n",
    "        \n",
    "        for x_i, y_i in zip(X.index, y.index):\n",
    "            text = X.loc[x_i].split()\n",
    "            for word in text:\n",
    "                word_locality_features[y.loc[y_i]][word] += 1\n",
    "                word_locality_features[y.loc[y_i]]['Total'] += 1\n",
    "                word_locality_features['Total'][word] += 1\n",
    "                word_locality_features['Total']['Total'] += 1\n",
    "        \n",
    "        for label in self.classes:\n",
    "            for word in word_locality_features[label].keys():\n",
    "                cond_word_prob = word_locality_features[label][word] / word_locality_features[label]['Total']\n",
    "                word_prob = word_locality_features['Total'][word] / word_locality_features['Total']['Total']\n",
    "                word_locality_weight[label][word] = cond_word_prob / word_prob\n",
    "        \n",
    "        features = []\n",
    "        for location in self.classes:\n",
    "            n_location_features = int(self.n_features / len(self.classes))\n",
    "            features.append(sorted(word_locality_weight[location].items(), key=lambda kv: kv[1], reverse=True)[:n_location_features]) \n",
    "        \n",
    "        self.features = set([feature[0] for feature in features])\n",
    "                \n",
    "    \n",
    "    def information_gain_ratio(self, x):\n",
    "#         return info_gain_ratio\n",
    "        pass\n",
    "    \n",
    "    def term_frequency_inverse_city_frequency(self, X, y):\n",
    "        vectorizer = TfidfVectorizer(stop_words=self.stop_words, max_features=self.n_features)\n",
    "\n",
    "        location_word_list = {label: '' for label in self.classes}\n",
    "\n",
    "        for x_i, y_i in zip(X.index, y.index):\n",
    "            location_word_list[y.loc[y_i]] += X.loc[x_i] + \" \"\n",
    "        \n",
    "        labels = location_word_list.keys()\n",
    "        corpus = location_word_list.values()\n",
    "        vectorizer.fit(corpus, labels)\n",
    "        self.features = set(vectorizer.get_feature_names())\n",
    "        \n",
    "    def filter(self, x):\n",
    "        return x.apply(self.filter_text)\n",
    "    \n",
    "    def filter_text(self, text):\n",
    "        return ' '.join(self.filter_word(w) for w in text.split())\n",
    "        \n",
    "    def filter_word(self, word):\n",
    "        word = word.lower()\n",
    "        # extract keywords from hashtag \n",
    "\n",
    "        if self._is_hyperlink(word):\n",
    "            return ''\n",
    "        elif self._is_hashtag(word):\n",
    "            word = self._process_hashtag(word)\n",
    "        # potentially cross-reference individuals mentioned? or discard\n",
    "        elif self._is_mention(word):\n",
    "            word = self._process_mention(word)\n",
    "        # remove ascii characters \n",
    "        else:\n",
    "            word = self._ascii_to_unicode(word)\n",
    "            \n",
    "            word = re.sub(r'[^\\w\\s]',' ', word)\n",
    "#             word = self._word_stem(word)\n",
    "            if word in self.stop_words:\n",
    "                return ''\n",
    "        return word\n",
    "                \n",
    "    def _is_hashtag(self, word):\n",
    "        if len(word) == 0:\n",
    "            return False\n",
    "        return word[0] == \"#\"\n",
    "    \n",
    "    def _is_mention(self, word):\n",
    "        if len(word) == 0:\n",
    "            return False\n",
    "        return word[0] == \"@\"\n",
    "    \n",
    "    def _is_hyperlink(self, word):\n",
    "        return validators.url(word)\n",
    "    \n",
    "    def _process_hashtag(self, word):\n",
    "        return word[1:]\n",
    "    \n",
    "    def _process_mention(self, word):\n",
    "        return word[1:]\n",
    "    \n",
    "    def _ascii_to_unicode(self, word):\n",
    "        for uescape in re.findall(r'(\\\\u[0-9a-f]{4})', word):\n",
    "            try:\n",
    "                word = word.replace(uescape, '')  \n",
    "            except (UnicodeDecodeError, Exception):\n",
    "                print(\"Failed to decode: {}\".format(uescape))\n",
    "        return word\n",
    "    \n",
    "    def _word_stem(self, word):\n",
    "        return self.stemmer.stem(word)\n",
    "\n",
    "class MetaClassifier:\n",
    "    def __init__(self, estimators, random_state):\n",
    "        self.estimators = estimators\n",
    "        self.encoder = OneHotEncoder()\n",
    "        self.base_classifier = svm.LinearSVC(random_state=random_state)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        y_set = pd.DataFrame(index=X.index, columns=[item[0] for item in self.estimators])\n",
    "        \n",
    "        for name, classifier in self.estimators:\n",
    "            classifier.fit(X, y)\n",
    "            y_bar = classifier.predict(X)\n",
    "            y_set[name] = self.encoder.fit_transform(y_bar.reshape(-1, 1)).toarray()\n",
    "            \n",
    "        self.base_classifier.fit(y_set, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_set = pd.DataFrame(index=X.index, columns=[item[0] for item in self.estimators])\n",
    "\n",
    "        for name, classifier in self.estimators:\n",
    "            y_bar = classifier.predict(X)\n",
    "            y_set[name] = self.encoder.transform(y_bar.reshape(-1, 1)).toarray()\n",
    "                \n",
    "        return  self.base_classifier.predict(y_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One-R', 'LinearSVM']\n",
      "Time taken: 0:07:55.846981\n",
      "Time taken: 0:02:43.710761\n"
     ]
    }
   ],
   "source": [
    "# classifier_set = [\"One-R\"]\n",
    "classifier_set = [\"One-R\", \"LinearSVM\"]\n",
    "print(classifier_set)\n",
    "voting_strategy = \"simple_voting\"\n",
    "combine_classifiers = True\n",
    "\n",
    "gt = GeoTagger(\n",
    "    inputs = inputs,\n",
    "    target = output,\n",
    "    classifier_set = classifier_set,\n",
    "    ensemble_strategy = voting_strategy,\n",
    "    feature_selection_method = \"tf_idf\",\n",
    "    seed = 500,\n",
    "    combine_classifiers = combine_classifiers\n",
    ")\n",
    "\n",
    "start = datetime.now()\n",
    "gt.train(x_train, y_train)\n",
    "end = datetime.now()\n",
    "print(\"Time taken: {}\".format(end - start))\n",
    "\n",
    "gt2 = GeoTagger(\n",
    "    inputs = inputs,\n",
    "    target = output,\n",
    "    classifier_set = classifier_set,\n",
    "    ensemble_strategy = voting_strategy,\n",
    "    feature_selection_method = \"baseline_10\",\n",
    "    seed = 500,\n",
    "    combine_classifiers = combine_classifiers\n",
    ")\n",
    "\n",
    "start = datetime.now()\n",
    "gt2.train(x_train, y_train)\n",
    "end = datetime.now()\n",
    "print(\"Time taken: {}\".format(end - start))\n",
    "\n",
    "gt3 = GeoTagger(\n",
    "    inputs = inputs,\n",
    "    target = output,\n",
    "    classifier_set = classifier_set,\n",
    "    ensemble_strategy = voting_strategy,\n",
    "    feature_selection_method = \"baseline_50\",\n",
    "    seed = 500,\n",
    "    combine_classifiers = combine_classifiers\n",
    ")\n",
    "\n",
    "start = datetime.now()\n",
    "gt3.train(x_train, y_train)\n",
    "end = datetime.now()\n",
    "print(\"Time taken: {}\".format(end - start))\n",
    "\n",
    "gt4 = GeoTagger(\n",
    "    inputs = inputs,\n",
    "    target = output,\n",
    "    classifier_set = classifier_set,\n",
    "    ensemble_strategy = voting_strategy,\n",
    "    feature_selection_method = \"baseline_100\",\n",
    "    seed = 500,\n",
    "    combine_classifiers = combine_classifiers\n",
    ")\n",
    "\n",
    "start = datetime.now()\n",
    "gt4.train(x_train, y_train)\n",
    "end = datetime.now()\n",
    "print(\"Time taken: {}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the class labels of a set of test data\n",
    "ybars = gt.predict(x_dev)\n",
    "ybars2 = gt2.predict(x_dev)\n",
    "ybars3 = gt3.predict(x_dev)\n",
    "ybars4 = gt4.predict(x_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [gt, gt2, gt3, gt4]\n",
    "# predictions = [ybars, ybars2, ybars3, ybars4]\n",
    "# evals = [\"accuracy\", \"precision_recall_f-score_with_micro\"]\n",
    "\n",
    "# for model, prediction in zip(models, predictions):\n",
    "#     for method in evals:\n",
    "#         report, confusion = model.evaluate(prediction, y_dev, method)\n",
    "#         print(\"{}: {}\".format(method, report, ))\n",
    "accScores = gt.evaluate(ybars, y_dev)\n",
    "# otherScores = gt.evaluate(ybars, y_dev, \"precision_recall_f-score_with_micro\")\n",
    "accScores2 = gt2.evaluate(ybars2, y_dev)\n",
    "# otherScores2 = gt2.evaluate(ybars2, y_dev, \"precision_recall_f-score_with_micro\")\n",
    "accScores3 = gt3.evaluate(ybars3, y_dev)\n",
    "# otherScores3 = gt3.evaluate(ybars3, y_dev, \"precision_recall_f-score_with_micro\")\n",
    "accScores4 = gt4.evaluate(ybars4, y_dev)\n",
    "# otherScores4 = gt4.evaluate(ybars4, y_dev, \"precision_recall_f-score_with_micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'One-R': 0.2693029490616622, 'Decision-Tree': 0.3017426273458445, 'MultinomialNB': 0.31847184986595173, 'LinearSVM': 0.3174530831099196}) defaultdict(None, {'One-R': 0.2693029490616622, 'Decision-Tree': 0.3152278820375335, 'MultinomialNB': 0.3106166219839142, 'LinearSVM': 0.31549597855227884}) defaultdict(None, {'One-R': 0.2693029490616622, 'Decision-Tree': 0.31056300268096515, 'MultinomialNB': 0.3155495978552279, 'LinearSVM': 0.3202412868632708}) defaultdict(None, {'One-R': 0.2693029490616622, 'Decision-Tree': 0.3124128686327078, 'MultinomialNB': 0.326970509383378, 'LinearSVM': 0.3225469168900804})\n"
     ]
    }
   ],
   "source": [
    "print(accScores, accScores2, accScores3, accScores4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['Brisbane', 'Melbourne', 'Perth', 'Sydney'], dtype=object), array([62648, 27532, 26591, 32429], dtype=int64))\n",
      "(array(['Brisbane', 'Melbourne', 'Perth', 'Sydney'], dtype=object), array([71147, 57048, 15850,  5155], dtype=int64))\n",
      "(array(['Brisbane', 'Melbourne', 'Perth', 'Sydney'], dtype=object), array([64150, 22852, 11545, 50653], dtype=int64))\n",
      "(array(['Brisbane', 'Melbourne', 'Perth', 'Sydney'], dtype=object), array([69120, 18512, 19236, 42332], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(ybars, return_counts=True))\n",
    "print(np.unique(ybars2, return_counts=True))\n",
    "print(np.unique(ybars3, return_counts=True))\n",
    "print(np.unique(ybars4, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Instance_ID\n",
       "21                                               You's suit\n",
       "22        @KellyFrye @girlscouts when life gives you coo...\n",
       "23                        @noviarezki naaaah itu dia hahaha\n",
       "24        #LouisWhyAreYouAnEGG  bro whyyy??? http://t.co...\n",
       "25        @9NewsBrisbane Why do we have to put up with a...\n",
       "26        \\Twt: 20 creepy kids' drawings that will haunt...\n",
       "27        Temp: 21.5\\u00b0C. Wind:11.5km/h. Pressure: 10...\n",
       "28                        In situ... http://t.co/X96m46OuOL\n",
       "29        An out-of-sessions court hearing will be held ...\n",
       "210       Saye laper! Betul betul laper! (with anandita,...\n",
       "211       T-MINUS 24 HOURS #igsg #\\u8981graduate\\u54af @...\n",
       "212       S P O T L I G H T \\ud83d\\udd06 we feel it's a ...\n",
       "213       I never understand how singers look so good in...\n",
       "214       @LTUcareers Trying to sign up for Career Ready...\n",
       "215       AU : Preventing suicide \\u2013 \\u201cno greate...\n",
       "216       \\u201c@MargsLD: One virginal Scottish hunk \\u2714\n",
       "217                        @TydeLevi obvssssss \\ud83d\\udc9e\n",
       "218                      night all enjoyable evening again.\n",
       "219       @xerexex please share our piece on our favouri...\n",
       "220       The dorkiest dorks that ever lived\\ud83d\\ude18...\n",
       "221       @dale_roots It's confusing for me, twice I've ...\n",
       "222       @AndyHowe_statto @BrentonSpeed @behindthegamep...\n",
       "223       I have finished #HouseofCards Season 3. Let's ...\n",
       "224       @heidi_masters they usually have a heap on sal...\n",
       "225       first shift back at maccas in 2 months. gets p...\n",
       "226       @HuffingtonPost wish I was there to help #STOP...\n",
       "227        Shenwari afganistan v Bangladesh #CastrolCatches\n",
       "228       @GlennJ1989 yeah good point, people in this co...\n",
       "229       @simpppqueen no offense to you but I can wait ...\n",
       "230                Nah tuk @DibEmail http://t.co/u7BPoy68Kx\n",
       "                                ...                        \n",
       "237287    @benwaterer1 @OliverShirley1 I'm 11 hours infr...\n",
       "237288    @osaka_nofu \\u304d\\u3063\\u3061\\u308a\\u7dbf\\u5b...\n",
       "237289     Big thumbs up to Nightcliff football club #qanda\n",
       "237290    .@WestCoastEagles coach Adam Simpson \\Geez we ...\n",
       "237291    @MSASHLEYVEE Do I need to buy tickets for tomo...\n",
       "237292                   Stay , stay , stay....\\ud83c\\udfb6\n",
       "237293    Drinking a Paradise Pale by @SEVENSHEDS @ Hop ...\n",
       "237294    #Australia build giant #record of 417 in #Worl...\n",
       "237295                           Messinger double to cf #3s\n",
       "237296                        N\\u00e3o aguento mais escola.\n",
       "237297    Jetset babies #virginaustralia #runwaychic #fl...\n",
       "237298    There's nothing better than crisp clean sheets...\n",
       "237299    I freaked out, 'cause the internet wasn't work...\n",
       "237300    Next week itinerary Melbourne &gt; Sydney &gt;...\n",
       "237301    just want to curl up into a ball nd sleep for ...\n",
       "237302    @pleasedontatme that's what I thought. But the...\n",
       "237303                               @Kowth aw thank you ^^\n",
       "237304    My life would be easier if I could afford styl...\n",
       "237305    \\u3058\\u3047\\u306b\\u8981\\u3089\\u306a\\u3044\\u30...\n",
       "237306    Congrats to the Taipans 4 making NBL GF last n...\n",
       "237307                             @nanexllc crash you mean\n",
       "237308    @GlennFrey - Thank You for the picks - you mad...\n",
       "237309    .@AECOSurgery @AlanCarlsonMD Great advice for ...\n",
       "237310    @vline_bendigo so did all that. Got an automat...\n",
       "237311             Oh sweet baby jebus, I am so content rn.\n",
       "237312    I'm  tired already  HAHA lets hope i won't  sl...\n",
       "237313    Es incre\\u00edble lo nefastos que pueden ser a...\n",
       "237314    @Be11eBunny @Lady_ofLegend what YOUZ think of ...\n",
       "237315    @suchisbeer that's silly. Which reminds me, di...\n",
       "237316                               http://t.co/CamU0sqyLg\n",
       "Name: Text, Length: 37300, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Resources\n",
    "- https://medium.com/@bedigunjit/simple-guide-to-text-classification-nlp-using-svm-and-naive-bayes-with-python-421db3a72d34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPreds = gt.predict(x_test)\n",
    "testPreds4 = gt4.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "accScoresTest = gt.evaluate(ybars, y_dev)\n",
    "accScoresTest4 = gt4.evaluate(ybars, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>One-R</th>\n",
       "      <th>Decision-Tree</th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <th>LinearSVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Perth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Perth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Perth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Perth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Perth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108112</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108113</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108114</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108115</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108116</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108117</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108118</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108119</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108120</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108121</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108122</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108123</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Perth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108124</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108125</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108126</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108127</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108128</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108129</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108130</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108131</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108132</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108133</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Perth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108134</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108135</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108136</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108137</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108138</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108139</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108140</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108141</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Perth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108142 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           One-R Decision-Tree MultinomialNB  LinearSVM\n",
       "0       Brisbane         Perth         Perth   Brisbane\n",
       "1       Brisbane         Perth        Sydney     Sydney\n",
       "2       Brisbane        Sydney        Sydney     Sydney\n",
       "3       Brisbane     Melbourne     Melbourne  Melbourne\n",
       "4       Brisbane        Sydney        Sydney     Sydney\n",
       "5       Brisbane         Perth     Melbourne     Sydney\n",
       "6       Brisbane     Melbourne     Melbourne  Melbourne\n",
       "7       Brisbane     Melbourne      Brisbane   Brisbane\n",
       "8       Brisbane         Perth      Brisbane      Perth\n",
       "9       Brisbane      Brisbane     Melbourne  Melbourne\n",
       "10      Brisbane         Perth        Sydney     Sydney\n",
       "11      Brisbane      Brisbane      Brisbane   Brisbane\n",
       "12      Brisbane        Sydney        Sydney     Sydney\n",
       "13      Brisbane     Melbourne     Melbourne  Melbourne\n",
       "14      Brisbane     Melbourne        Sydney     Sydney\n",
       "15      Brisbane     Melbourne      Brisbane      Perth\n",
       "16      Brisbane     Melbourne     Melbourne      Perth\n",
       "17      Brisbane         Perth         Perth      Perth\n",
       "18      Brisbane         Perth      Brisbane     Sydney\n",
       "19      Brisbane      Brisbane      Brisbane   Brisbane\n",
       "20      Brisbane      Brisbane        Sydney     Sydney\n",
       "21      Brisbane        Sydney        Sydney     Sydney\n",
       "22      Brisbane        Sydney        Sydney      Perth\n",
       "23      Brisbane     Melbourne         Perth     Sydney\n",
       "24      Brisbane      Brisbane        Sydney     Sydney\n",
       "25      Brisbane     Melbourne     Melbourne      Perth\n",
       "26      Brisbane         Perth        Sydney      Perth\n",
       "27      Brisbane      Brisbane     Melbourne  Melbourne\n",
       "28      Brisbane      Brisbane      Brisbane   Brisbane\n",
       "29      Brisbane     Melbourne        Sydney     Sydney\n",
       "...          ...           ...           ...        ...\n",
       "108112  Brisbane         Perth     Melbourne  Melbourne\n",
       "108113  Brisbane     Melbourne      Brisbane   Brisbane\n",
       "108114  Brisbane     Melbourne     Melbourne  Melbourne\n",
       "108115  Brisbane      Brisbane      Brisbane   Brisbane\n",
       "108116  Brisbane     Melbourne         Perth  Melbourne\n",
       "108117  Brisbane      Brisbane     Melbourne   Brisbane\n",
       "108118  Brisbane      Brisbane     Melbourne     Sydney\n",
       "108119  Brisbane         Perth     Melbourne  Melbourne\n",
       "108120  Brisbane        Sydney        Sydney     Sydney\n",
       "108121  Brisbane         Perth      Brisbane  Melbourne\n",
       "108122  Brisbane         Perth      Brisbane     Sydney\n",
       "108123  Brisbane         Perth         Perth      Perth\n",
       "108124  Brisbane        Sydney        Sydney     Sydney\n",
       "108125  Brisbane      Brisbane     Melbourne   Brisbane\n",
       "108126  Brisbane      Brisbane      Brisbane   Brisbane\n",
       "108127  Brisbane      Brisbane      Brisbane   Brisbane\n",
       "108128  Brisbane         Perth      Brisbane     Sydney\n",
       "108129  Brisbane         Perth      Brisbane     Sydney\n",
       "108130  Brisbane         Perth      Brisbane   Brisbane\n",
       "108131  Brisbane         Perth        Sydney     Sydney\n",
       "108132  Brisbane      Brisbane        Sydney  Melbourne\n",
       "108133  Brisbane     Melbourne         Perth      Perth\n",
       "108134  Brisbane        Sydney        Sydney     Sydney\n",
       "108135  Brisbane     Melbourne     Melbourne  Melbourne\n",
       "108136  Brisbane        Sydney      Brisbane   Brisbane\n",
       "108137  Brisbane         Perth        Sydney     Sydney\n",
       "108138  Brisbane        Sydney     Melbourne  Melbourne\n",
       "108139  Brisbane         Perth     Melbourne   Brisbane\n",
       "108140  Brisbane        Sydney      Brisbane   Brisbane\n",
       "108141  Brisbane         Perth         Perth      Perth\n",
       "\n",
       "[108142 rows x 4 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>One-R</th>\n",
       "      <th>Decision-Tree</th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <th>LinearSVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Perth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108112</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108113</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108114</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108115</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108116</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108117</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108118</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108119</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108120</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108121</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108122</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108123</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108124</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108125</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108126</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108127</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108128</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108129</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108130</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108131</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108132</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108133</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108134</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108135</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Perth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108136</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Melbourne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108137</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108138</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108139</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108140</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108141</th>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108142 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           One-R Decision-Tree MultinomialNB  LinearSVM\n",
       "0       Brisbane        Sydney        Sydney     Sydney\n",
       "1       Brisbane        Sydney        Sydney     Sydney\n",
       "2       Brisbane        Sydney        Sydney     Sydney\n",
       "3       Brisbane      Brisbane      Brisbane   Brisbane\n",
       "4       Brisbane         Perth      Brisbane     Sydney\n",
       "5       Brisbane         Perth      Brisbane     Sydney\n",
       "6       Brisbane      Brisbane        Sydney     Sydney\n",
       "7       Brisbane      Brisbane      Brisbane   Brisbane\n",
       "8       Brisbane        Sydney        Sydney     Sydney\n",
       "9       Brisbane        Sydney     Melbourne     Sydney\n",
       "10      Brisbane        Sydney        Sydney     Sydney\n",
       "11      Brisbane      Brisbane      Brisbane   Brisbane\n",
       "12      Brisbane         Perth        Sydney     Sydney\n",
       "13      Brisbane        Sydney     Melbourne  Melbourne\n",
       "14      Brisbane      Brisbane      Brisbane   Brisbane\n",
       "15      Brisbane     Melbourne        Sydney   Brisbane\n",
       "16      Brisbane     Melbourne        Sydney  Melbourne\n",
       "17      Brisbane     Melbourne         Perth  Melbourne\n",
       "18      Brisbane        Sydney        Sydney     Sydney\n",
       "19      Brisbane      Brisbane      Brisbane   Brisbane\n",
       "20      Brisbane      Brisbane        Sydney     Sydney\n",
       "21      Brisbane      Brisbane      Brisbane   Brisbane\n",
       "22      Brisbane      Brisbane        Sydney     Sydney\n",
       "23      Brisbane      Brisbane         Perth      Perth\n",
       "24      Brisbane     Melbourne        Sydney  Melbourne\n",
       "25      Brisbane         Perth      Brisbane     Sydney\n",
       "26      Brisbane         Perth      Brisbane     Sydney\n",
       "27      Brisbane      Brisbane      Brisbane   Brisbane\n",
       "28      Brisbane        Sydney        Sydney     Sydney\n",
       "29      Brisbane      Brisbane      Brisbane   Brisbane\n",
       "...          ...           ...           ...        ...\n",
       "108112  Brisbane     Melbourne         Perth  Melbourne\n",
       "108113  Brisbane         Perth         Perth     Sydney\n",
       "108114  Brisbane     Melbourne     Melbourne  Melbourne\n",
       "108115  Brisbane      Brisbane      Brisbane   Brisbane\n",
       "108116  Brisbane         Perth         Perth  Melbourne\n",
       "108117  Brisbane     Melbourne        Sydney  Melbourne\n",
       "108118  Brisbane         Perth      Brisbane     Sydney\n",
       "108119  Brisbane      Brisbane      Brisbane   Brisbane\n",
       "108120  Brisbane        Sydney        Sydney     Sydney\n",
       "108121  Brisbane     Melbourne      Brisbane     Sydney\n",
       "108122  Brisbane         Perth      Brisbane     Sydney\n",
       "108123  Brisbane         Perth      Brisbane     Sydney\n",
       "108124  Brisbane        Sydney        Sydney     Sydney\n",
       "108125  Brisbane        Sydney        Sydney     Sydney\n",
       "108126  Brisbane        Sydney        Sydney     Sydney\n",
       "108127  Brisbane      Brisbane      Brisbane   Brisbane\n",
       "108128  Brisbane         Perth      Brisbane     Sydney\n",
       "108129  Brisbane         Perth      Brisbane     Sydney\n",
       "108130  Brisbane         Perth      Brisbane     Sydney\n",
       "108131  Brisbane     Melbourne        Sydney  Melbourne\n",
       "108132  Brisbane        Sydney      Brisbane  Melbourne\n",
       "108133  Brisbane         Perth        Sydney  Melbourne\n",
       "108134  Brisbane     Melbourne     Melbourne  Melbourne\n",
       "108135  Brisbane      Brisbane        Sydney      Perth\n",
       "108136  Brisbane      Brisbane      Brisbane  Melbourne\n",
       "108137  Brisbane      Brisbane        Sydney     Sydney\n",
       "108138  Brisbane      Brisbane         Perth     Sydney\n",
       "108139  Brisbane        Sydney        Sydney     Sydney\n",
       "108140  Brisbane      Brisbane      Brisbane   Brisbane\n",
       "108141  Brisbane      Brisbane      Brisbane   Brisbane\n",
       "\n",
       "[108142 rows x 4 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPreds4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testMNB100 = test.copy()\n",
    "testMNB100[output] = testPreds4[\"MultinomialNB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
